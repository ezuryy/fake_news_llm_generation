{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f3380f-ac2c-4b22-842d-e5389cf441cb",
   "metadata": {},
   "source": [
    "# Automatic metrics \n",
    "\n",
    "Metrics, used for evaluating the quality of generated texts\n",
    "\n",
    "- [x] ROUGE-1_recall\n",
    "- [x] ROUGE-2_recall\n",
    "- [x] ROUGE-L_recall\n",
    "- [x] BLEU\n",
    "- [x] METEOR\n",
    "- [x] Perplexity \n",
    "- [x] BERTscore_precision\n",
    "- [x] BERTscore_recall\n",
    "- [x] BERTscore_f1\n",
    "- [x] BLEURT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcb561e-1c16-4450-8d73-9e356a1e3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52c19e-0f83-4b5a-a50d-6443df986b6c",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "\n",
    "$$Perplexity = \\exp \\bigl(- \\frac{1}{N} \\sum_{i=0}^{N} \\log P(x_i | x_0, ..., x_{i-1})\\bigr) =  \\exp (\\text{ouputs.loss})$$\n",
    "\n",
    "$$\\text{ouputs.loss} = - \\frac{1}{N} \\sum_{i=0}^{N} \\log P(x_i | x_0, ..., x_{i-1})$$\n",
    "\n",
    "$$ P(x_i | x_0, ..., x_{i-1}) = Softmax (\\text{ouputs.logits})$$\n",
    "\n",
    "$$Softmax (x_i) = \\frac{e^{x_i}}{\\sum_{j}e^{x_j}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67997f35-fbe5-4589-8a64-098f03fa4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "\n",
    "ppl_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ppl_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "ppl_model.to(DEVICE)\n",
    "ppl_model.eval()\n",
    "\n",
    "def get_loss(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    text: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates loss: - mean of log p(x_i | x_0, ..., x_{i - 1})\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def calculate_perplexity(loss: torch.tensor):\n",
    "    \"\"\"\n",
    "    Calculates perplexity: exp( - mean of log p(x_i | x_0, ..., x_{i - 1}))\n",
    "    \"\"\"\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return perplexity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0171e5-7655-4153-885c-f4442ab5b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert calculate_perplexity(torch.tensor(0.)) == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b94e0c3-fbe5-4240-86df-0417e742c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(calculate_perplexity(torch.tensor(1.)), 5) == 2.71828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03115896-a48d-4f68-843b-9d81ffd755f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "202.2754669189453"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(get_loss(ppl_model, ppl_tokenizer, \"Кот съел рыбу.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f276b-75b1-4ca1-85a9-7d4ab3b6ed86",
   "metadata": {},
   "source": [
    "## ROUGE \n",
    "\n",
    "<!-- $$\\text{ROUGE-N} = \\frac{\\text{Common n-gramm count}}{\\text{Count of all n-gramm in reference}}$$ -->\n",
    "\n",
    "\n",
    "$$ \n",
    "ROUGE^N_{recall} = \\frac{\\textit{N-grams that appear in both R and C}}{\\textit{N-grams in R}}\n",
    "$$ \n",
    "\n",
    "$$ \n",
    "ROUGE^N_{precision} = \\frac{\\textit{N-grams that appear in both R and C}}{\\textit{N-grams in C}}\n",
    "$$ \n",
    "\n",
    "$$ \n",
    "ROUGE^N_{F_1} = \\frac{2 \\cdot ROUGE^N_{recall} \\cdot ROUGE^N_{precision}}{ROUGE^N_{recall} + ROUGE^N_{precision}}\n",
    "$$ \n",
    "\n",
    "$R$ - reference, \n",
    "\n",
    "$C$ - candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adde4d1-8d77-4baf-84e1-d50e67c9049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 Precision: 1.0000\n",
      "ROUGE-1 Recall: 0.7500\n",
      "ROUGE-1 F1 Score: 0.8571\n",
      "\n",
      "ROUGE-2 Precision: 0.5000\n",
      "ROUGE-2 Recall: 0.3333\n",
      "ROUGE-2 F1 Score: 0.4000\n",
      "\n",
      "ROUGE-L LCS Length: 3\n",
      "ROUGE-L Precision: 1.0000\n",
      "ROUGE-L Recall: 0.7500\n",
      "ROUGE-L F1 Score: 0.8571\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "\n",
    "def preprocess_text(text: str, stemmer: SnowballStemmer = stemmer):\n",
    "    \"\"\"\n",
    "    Uses stemming to transform words into initial form\n",
    "    \"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator).lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    stems = [stemmer.stem(word) for word in words]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def rouge_n(cand_stems: tp.List[str], ref_stems: tp.List[str], n: int = 1):\n",
    "    \"\"\"\n",
    "    Calculates ROUGE-N for given n. Uses stems - lists of words in initial form \n",
    "    \"\"\"\n",
    "    candidate_ngrams = list(ngrams(cand_stems, n))\n",
    "    reference_ngrams = list(ngrams(ref_stems, n))\n",
    "    \n",
    "    ref_counts = defaultdict(int)\n",
    "    for gram in reference_ngrams:\n",
    "        ref_counts[gram] += 1\n",
    "    \n",
    "    overlap = 0\n",
    "    cand_counts = defaultdict(int)\n",
    "    for gram in candidate_ngrams:\n",
    "        cand_counts[gram] += 1\n",
    "        if cand_counts[gram] <= ref_counts[gram]:\n",
    "            overlap += 1\n",
    "    \n",
    "    precision = overlap / len(candidate_ngrams) if candidate_ngrams else 0\n",
    "    recall = overlap / len(reference_ngrams) if reference_ngrams else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge-{}_precision'.format(n): precision,\n",
    "        'rouge-{}_recall'.format(n): recall,\n",
    "        'rouge-{}_f1'.format(n): f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def lcs_rec(s1: tp.List[str], s2: tp.List[str], m: int, n: int, memo: tp.List[tp.List[int]]):\n",
    "    \"\"\"\n",
    "    Calculates LCS (Longest Common Subsequence) using dynamic programming\n",
    "    \"\"\"\n",
    "    if m == 0 or n == 0:\n",
    "        return 0\n",
    "\n",
    "    if memo[m][n] != -1:\n",
    "        return memo[m][n]\n",
    "\n",
    "    if s1[m - 1] == s2[n - 1]:\n",
    "        memo[m][n] = 1 + lcs_rec(s1, s2, m - 1, n - 1, memo)\n",
    "        return memo[m][n]\n",
    "\n",
    "    memo[m][n] = max(lcs_rec(s1, s2, m, n - 1, memo),\n",
    "                     lcs_rec(s1, s2, m - 1, n, memo))\n",
    "    return memo[m][n]\n",
    "\n",
    "\n",
    "def lcs(s1: tp.List[str], s2: tp.List[str]):\n",
    "    \"\"\"\n",
    "    Calculates LCS (Longest Common Subsequence)\n",
    "    \"\"\"\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    memo = [[-1 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    return lcs_rec(s1, s2, m, n, memo)\n",
    "\n",
    "\n",
    "def rouge_l(cand_stems: tp.List[str], ref_stems: tp.List[str]):\n",
    "    \"\"\"\n",
    "    Calculates ROUGE-L using LCS function for numerator calculation. \n",
    "    Uses stems - lists of words in initial form \n",
    "    \"\"\"\n",
    "    lcs_length = lcs(cand_stems, ref_stems)\n",
    "    \n",
    "    precision = lcs_length / len(cand_stems) if len(cand_stems) > 0 else 0\n",
    "    recall = lcs_length / len(ref_stems) if len(ref_stems) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'rouge-l_lcs_length': lcs_length,\n",
    "        'rouge-l_precision': precision,\n",
    "        'rouge-l_recall': recall,\n",
    "        'rouge-l_f1': f1\n",
    "    }\n",
    "\n",
    "candidate = \"кот рыба ел\"\n",
    "reference = \"кот рыба стол ел\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "print(f\"ROUGE-1 Precision: {result['rouge-1_precision']:.4f}\")\n",
    "print(f\"ROUGE-1 Recall: {result['rouge-1_recall']:.4f}\")\n",
    "print(f\"ROUGE-1 F1 Score: {result['rouge-1_f1']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(f\"ROUGE-2 Precision: {result['rouge-2_precision']:.4f}\")\n",
    "print(f\"ROUGE-2 Recall: {result['rouge-2_recall']:.4f}\")\n",
    "print(f\"ROUGE-2 F1 Score: {result['rouge-2_f1']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(f\"ROUGE-L LCS Length: {result['rouge-l_lcs_length']}\")\n",
    "print(f\"ROUGE-L Precision: {result['rouge-l_precision']:.4f}\")\n",
    "print(f\"ROUGE-L Recall: {result['rouge-l_recall']:.4f}\")\n",
    "print(f\"ROUGE-L F1 Score: {result['rouge-l_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004552b6-e1ce-4407-9a8a-a35296cce289",
   "metadata": {},
   "source": [
    "### LCS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0c40e5-12ff-433b-9b92-9df8148a4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lcs([x for x in \"ABC\"], [x for x in \"ACD\"]) == 2\n",
    "assert lcs([x for x in \"AGGTAB\"], [x for x in \"GXTXAYB\"]) == 4\n",
    "assert lcs([x for x in \"ABC\"], [x for x in \"CBA\"]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6ed46a-da6c-461c-90e6-61d070957611",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lcs([x for x in \"abcde\"], [x for x in \"ace\"]) == 3\n",
    "assert lcs([x for x in \"abc\"], [x for x in \"abc\"]) == 3\n",
    "assert lcs([x for x in \"abc\"], [x for x in \"def\"]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828a030-4c60-440d-8d78-0625fd16f344",
   "metadata": {},
   "source": [
    "### ROUGE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2694a34b-6e5a-4d9e-8430-d379332fe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"Собака бежит по полю\"\n",
    "reference = \"Собака бежит по полю\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "target_result = {\n",
    "    'rouge-1_precision': 1.0,\n",
    "    'rouge-1_recall': 1.0,\n",
    "    'rouge-1_f1': 1.0,\n",
    "    \n",
    "    'rouge-2_precision': 1.0,\n",
    "    'rouge-2_recall': 1.0,\n",
    "    'rouge-2_f1': 1.0,\n",
    "    \n",
    "    'rouge-l_lcs_length': 4,\n",
    "    'rouge-l_precision': 1.0,\n",
    "    'rouge-l_recall': 1.0,\n",
    "    'rouge-l_f1': 1.0\n",
    "}\n",
    "\n",
    "assert result == target_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42710d9a-8fe4-4c0a-ac3c-e449ceb6bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"Быстрый кот ест рыбу\"\n",
    "reference = \"Рыжий кот ест рыбу\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "target_result = {\n",
    "    'rouge-1_precision': 0.75,\n",
    "    'rouge-1_recall': 0.75,\n",
    "    'rouge-1_f1': 0.75,\n",
    "    \n",
    "    'rouge-2_precision': 2 / 3,\n",
    "    'rouge-2_recall': 2 / 3,\n",
    "    'rouge-2_f1': 2 / 3,\n",
    "    \n",
    "    'rouge-l_lcs_length': 3,\n",
    "    'rouge-l_precision': 0.75,\n",
    "    'rouge-l_recall': 0.75,\n",
    "    'rouge-l_f1': 0.75\n",
    "}\n",
    "\n",
    "assert result == target_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de16a81b-1130-4dc4-82af-7c4d3ad13d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"Рыбу ест кот\"\n",
    "reference = \"Кот ест рыбу\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "target_result = {\n",
    "    'rouge-1_precision': 1,\n",
    "    'rouge-1_recall': 1,\n",
    "    'rouge-1_f1': 1,\n",
    "    \n",
    "    'rouge-2_precision': 0,\n",
    "    'rouge-2_recall': 0,\n",
    "    'rouge-2_f1': 0,\n",
    "    \n",
    "    'rouge-l_lcs_length': 1,\n",
    "    'rouge-l_precision': 1 / 3,\n",
    "    'rouge-l_recall': 1 / 3,\n",
    "    'rouge-l_f1': 1 / 3\n",
    "}\n",
    "\n",
    "assert result == target_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b2c64d-e8f7-47e3-8e23-e9f637166e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"Кот, кот, кот\"\n",
    "reference = \"Кот ест рыбу\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "target_result = {\n",
    "    'rouge-1_precision': 1 / 3,\n",
    "    'rouge-1_recall': 1 / 3,\n",
    "    'rouge-1_f1': 1 / 3,\n",
    "    \n",
    "    'rouge-2_precision': 0,\n",
    "    'rouge-2_recall': 0,\n",
    "    'rouge-2_f1': 0,\n",
    "    \n",
    "    'rouge-l_lcs_length': 1,\n",
    "    'rouge-l_precision': 1 / 3,\n",
    "    'rouge-l_recall': 1 / 3,\n",
    "    'rouge-l_f1': 1 / 3\n",
    "}\n",
    "\n",
    "assert result == target_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dd000b1-3435-4510-a2ab-29843b8e08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"\"\n",
    "reference = \"Пример? текста для: теста\"\n",
    "\n",
    "cand_stems = preprocess_text(candidate, stemmer)\n",
    "ref_stems = preprocess_text(reference, stemmer)\n",
    "\n",
    "rouge1 = rouge_n(cand_stems, ref_stems, n=1)\n",
    "rouge2 = rouge_n(cand_stems, ref_stems, n=2)\n",
    "rougel = rouge_l(cand_stems, ref_stems)\n",
    "result = rouge1 | rouge2 | rougel\n",
    "\n",
    "target_result = {\n",
    "    'rouge-1_precision': 0,\n",
    "    'rouge-1_recall': 0,\n",
    "    'rouge-1_f1': 0,\n",
    "    \n",
    "    'rouge-2_precision': 0,\n",
    "    'rouge-2_recall': 0,\n",
    "    'rouge-2_f1': 0,\n",
    "    \n",
    "    'rouge-l_lcs_length': 0,\n",
    "    'rouge-l_precision': 0,\n",
    "    'rouge-l_recall': 0,\n",
    "    'rouge-l_f1': 0\n",
    "}\n",
    "\n",
    "assert result == target_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f8d57-ddb9-42b4-a5e0-1af27fb95304",
   "metadata": {},
   "source": [
    "## BLEU\n",
    "\n",
    "<!-- $$\\text{BLEU} = \\text{BP} \\cdot \\bigl( \\sum_{n=1}^4 \\omega_n \\log p_n \\bigr)$$\n",
    "\n",
    "$$\\text{BP} = \\text{e} ^ {-max(0, \\frac{r}{c} - 1)}$$\n",
    "\n",
    "$$w_i = \\frac{1}{4}$$\n",
    "\n",
    "$c$ - the length of the stemmed candidate \n",
    "\n",
    "$r$ - effective reference length; sum of the best match lengths for each candidate sentence in the corpus (minimal length difference of reference and candidate texts)\n",
    "\n",
    "$p_n$ - n-gramm recall:\n",
    "\n",
    "$$p_n = \\frac{ \\sum_{\\text{stem-ngram} \\in C} \\min \\bigl( \\text{count}_C (\\text{stem-ngram}), \\max_{r \\in R} \\text{count}_r (\\text{stem-ngram}) \\bigr)}{\\sum_{\\text{stem-ngram} \\in C} \\text{count}_C (\\text{stem-ngram})}$$ -->\n",
    "\n",
    "$$\n",
    "BLEU = min \\Biggl(1, exp(1 - \\frac{len(reference)}{len(output)})\\Biggr)\n",
    "\\llap{\\underbrace{\\phantom{min  \\Biggl(1, exp(1 - \\frac{len(reference)}{len(output)})\\Biggr)}}_{\\text{brevity penalty }}}\n",
    "\\left( \\prod_{i = 1}^{4}precision_i\\right)^{1/4}\n",
    "\\llap{\\underbrace{\\phantom{\\left(\\prod_{i = 1}^{4}precision_i)^{1/4}\\right)}}_{\\text{n-gram overlap}}},\n",
    "$$\n",
    "\n",
    "$len(reference)$ - count of unigramms in reference,\n",
    "\n",
    "$len(output)$ - count of unigramms in candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f0566d-2cde-4d2b-a06e-51ccd05098c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc004c0-051d-46f6-9784-ba5b209f089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [1.0, 0.0, 0.0, 0.0],\n",
       " 'brevity_penalty': 0.6065306597126334,\n",
       " 'length_ratio': 0.6666666666666666,\n",
       " 'translation_length': 2,\n",
       " 'reference_length': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check en result equals ru result\n",
    "\n",
    "bleu_results_en = bleu_metric.compute(predictions=[\"cat rotate\"], references=[\"cat sees rotate\"])\n",
    "bleu_results_ru = bleu_metric.compute(predictions=[\"кот поворот\"], references=[\"кот видит поворот\"])\n",
    "\n",
    "assert bleu_results_ru == bleu_results_en\n",
    "bleu_results_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c47e1cd8-c91b-4503-be70-a0f08e867295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 4,\n",
       " 'reference_length': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check preprocess_text() removes punctuation and do stemming correctly\n",
    "\n",
    "predictions = \"Кот важный ел: - рыбу.\"\n",
    "references = \"Кот важно ел рыбу\"\n",
    "\n",
    "predictions = \" \".join(preprocess_text(predictions, stemmer))\n",
    "references = \" \".join(preprocess_text(references, stemmer))\n",
    "\n",
    "bleu_target = {\n",
    "    'bleu': 1.0,\n",
    "    'precisions': [1.0, 1.0, 1.0, 1.0],\n",
    "    'brevity_penalty': 1.0,\n",
    "    'length_ratio': 1.0,\n",
    "    'translation_length': 4,\n",
    "    'reference_length': 4\n",
    "}\n",
    "bleu_results = bleu_metric.compute(predictions=[predictions], references=[references])\n",
    "assert bleu_results == bleu_target\n",
    "\n",
    "bleu_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de2d57-7d22-4451-93d2-b2e53f9d5c88",
   "metadata": {},
   "source": [
    "Another way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9f499e-0af5-43f4-9afd-4e3ce037b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668740304976422\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['this', 'movie', 'was', 'awesome']]\n",
    "candidate = ['this', 'movie', 'was', 'awesome', 'too']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7281ae10-a394-4468-b328-6a6cfb788c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7788007830714049\n"
     ]
    }
   ],
   "source": [
    "score = sentence_bleu([\"этот кот сидел на ковре\".split()], \"кот сидел на ковре\".split())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1f4d3-7324-4f96-8d76-5291c8ed1293",
   "metadata": {},
   "source": [
    "## METEOR\n",
    "\n",
    "$$Precision = \\frac{m}{w_c}$$\n",
    "$$Recall = \\frac{m}{w_r} $$\n",
    "$$F_{mean} = \\frac{10 \\cdot Precision \\cdot Recall}{Recall + 10 \\cdot Precision}$$\n",
    "\n",
    "where $m$ - unigrams that appear in both Reference and Candidate,\n",
    "\n",
    "$w_c$ - unigrams in Candidate,\n",
    "\n",
    "$w_r$ - unigrams in Reference.\n",
    "\n",
    "$$p = 0.5 \\left( \\frac{c}{u_m} \\right)^3$$\n",
    "\n",
    "where $u_m$ – summary count of unigrams in Candidate.\n",
    "\n",
    "$$METEOR = F_{mean} (1 - p)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426631ca-e3a0-4f10-bd51-f3fb4fd5116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ezuryy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ezuryy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ezuryy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('meteor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3b0bd47-5390-4173-b32f-33ec4cbc84ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteor': np.float64(0.754985754985755)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check en result equals ru result\n",
    "\n",
    "results_en = meteor.compute(predictions=[\"text on english\"], references=[\"another text on english\"])\n",
    "results_ru = meteor.compute(predictions=[\"текст на русском\"], references=[\"другой текст на русском\"])\n",
    "\n",
    "assert results_ru == results_en\n",
    "\n",
    "results_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda3d79-bfde-424e-82cf-0d528cadcdb2",
   "metadata": {},
   "source": [
    "## BERTscore\n",
    " \n",
    "$$R_{\\text{BERT}} = \\frac{1}{|x|} \\sum_{x_i \\in x} \\max_{\\hat{x}_j \\in \\hat{x}} x_i^\\top \\hat{x}_j$$\n",
    "\n",
    "$$P_{\\text{BERT}} = \\frac{1}{|\\hat{x}|} \\sum_{\\hat{x}_j \\in \\hat{x}} \\max_{x_i \\in x} x_i^\\top \\hat{x}_j$$\n",
    "\n",
    "$$F_{\\text{BERT}} = \\frac{2 P_{\\text{BERT}} \\cdot R_{\\text{BERT}}}{P_{\\text{BERT}} + R_{\\text{BERT}}}$$\n",
    "\n",
    "$x$ - embedding of reference,\n",
    "\n",
    "$\\hat{x}$ - embedding of candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3b11b1-d748-49b5-8083-90c584762a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bertscore_model = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b7268b7-7b62-420f-b13c-94d9e8f01442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9174482822418213],\n",
       " 'recall': [0.9397120475769043],\n",
       " 'f1': [0.9284467101097107],\n",
       " 'hashcode': 'bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.49.0)'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = bertscore_model.compute(predictions=[\"текст на русском языке\"], references=[\"текст на русском\"], lang=\"ru\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "042b1afb-fc9c-4132-9c75-fca14bafb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bertscore(\n",
    "    model, \n",
    "    references: tp.List[str], \n",
    "    candidates: tp.List[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates BERTscore for pairs reference-candidate. \n",
    "    Returns mean BERTscore values.\n",
    "    \"\"\"\n",
    "    result_bertscore = model.compute(predictions=candidates, references=references, lang=\"ru\")\n",
    "    return {\n",
    "        \"BERTscore_precision\": round(float(np.mean(result_bertscore[\"precision\"])), 4),\n",
    "        \"BERTscore_recall\": round(float(np.mean(result_bertscore[\"recall\"])), 4),\n",
    "        \"BERTscore_f1\": round(float(np.mean(result_bertscore[\"f1\"])), 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39789f90-1c58-4c99-bd77-4e74f17e675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERTscore_precision': 0.9351,\n",
       " 'BERTscore_recall': 0.8923,\n",
       " 'BERTscore_f1': 0.9132}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equal texts\n",
    "calculate_bertscore(bertscore_model, [\"текст, на русском\"], [\"текст на русском\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714e72f7-2447-493a-bab1-d4e0072dc3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERTscore_precision': 0.9226,\n",
       " 'BERTscore_recall': 0.948,\n",
       " 'BERTscore_f1': 0.9351}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# almost equal texts\n",
    "calculate_bertscore(bertscore_model, [\"текст на русском\"], [\"другой текст на русском\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38aea750-df95-4d80-b538-28ff605433a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERTscore_precision': 0.5901,\n",
       " 'BERTscore_recall': 0.5988,\n",
       " 'BERTscore_f1': 0.5944}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different texts without common words\n",
    "calculate_bertscore(bertscore_model, [\"текст, на русском\"], [\"кот съел рыбку\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d08e824-61a3-4ae2-8fb0-934c450c54d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERTscore_precision': 0.8413,\n",
       " 'BERTscore_recall': 0.8261,\n",
       " 'BERTscore_f1': 0.8336}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different texts with common words\n",
    "calculate_bertscore(bertscore_model, [\"кот не съел собаку\"], [\"кот съел рыбку\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c18ff-bc10-4316-aab2-6ebd5d667529",
   "metadata": {},
   "source": [
    "## BLEURT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85268de9-5793-46a0-9bb7-a8c50bbbd620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BleurtSPTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from bleurt_pytorch import BleurtConfig, BleurtForSequenceClassification, BleurtTokenizer  \n",
    "import transformers\n",
    "\n",
    "\n",
    "bleurt_config = BleurtConfig.from_pretrained('lucadiliello/BLEURT-20-D12')  \n",
    "bleurt_model = BleurtForSequenceClassification.from_pretrained('lucadiliello/BLEURT-20-D12')  \n",
    "bleurt_tokenizer = BleurtTokenizer.from_pretrained('lucadiliello/BLEURT-20-D12')  \n",
    "\n",
    "bleurt_model.to(DEVICE)\n",
    "bleurt_model.eval() \n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "def calculate_bleurt(\n",
    "    model: BleurtForSequenceClassification, \n",
    "    tokenizer: BleurtTokenizer, \n",
    "    references: tp.List[str], \n",
    "    candidates: tp.List[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates BLEURT for pairs reference-candidate. \n",
    "    Returns mean BLEURT value.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  \n",
    "        inputs = tokenizer(\n",
    "            references, candidates, \n",
    "            max_length=512, \n",
    "            truncation=True, \n",
    "            padding='longest',\n",
    "            return_tensors='pt').to(DEVICE)\n",
    "        scores = model(**inputs).logits.flatten().tolist() \n",
    "    \n",
    "    return {\n",
    "        \"BLEURT\": round(float(np.mean(scores)), 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ade11d21-b634-4072-8788-3608316df103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLEURT': 0.8455}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleurt(bleurt_model, bleurt_tokenizer, [\"Кот съел рыбку\"], [\"Кот съел рыбину\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cb9c340-7b0b-4b65-8fea-b48fc2b7027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLEURT': 0.5484}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [\n",
    "    \"кошка лежит на ковре\",\n",
    "    \"нейронные сети развивают Natural Language Processing\"\n",
    "]\n",
    "\n",
    "candidates = [\n",
    "    \"котик лежит на коврике\",\n",
    "    \"нейросети улучшают обработку естественного языка\"\n",
    "]\n",
    "\n",
    "calculate_bleurt(bleurt_model, bleurt_tokenizer, references, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08b487-239a-4bad-80ef-c9af04121e90",
   "metadata": {},
   "source": [
    "# Apply metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a5aff0a-0a71-4cbd-800a-5eca4bf3d01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>len_cleaned_text</th>\n",
       "      <th>gen_llama3_8b</th>\n",
       "      <th>gen_llama3_8b_lora</th>\n",
       "      <th>gen_mistral_7b_lora</th>\n",
       "      <th>gen_mistral_7b</th>\n",
       "      <th>gen_qwen_7b</th>\n",
       "      <th>gen_qwen_7b_lora</th>\n",
       "      <th>gen_llama_8b</th>\n",
       "      <th>gen_yagpt_8b</th>\n",
       "      <th>gen_rugpt_13b</th>\n",
       "      <th>gen_tliteit_7b</th>\n",
       "      <th>gen_llama_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.fontanka.ru/2013/10/16/017/</td>\n",
       "      <td>Пожар произошел минувшей ночью в Московском ра...</td>\n",
       "      <td>На стоянке на Звездной обгорело семь машин</td>\n",
       "      <td>taiga_fontanka</td>\n",
       "      <td>1381911180</td>\n",
       "      <td>На стоянке на Звездной обгорело семь машин</td>\n",
       "      <td>Пожар произошел минувшей ночью в Московском ра...</td>\n",
       "      <td>476</td>\n",
       "      <td>```\\nВ результате пожара в ночном клубе «Мечта...</td>\n",
       "      <td>В ночь с 28-го апреля на 29-е в поселковом цен...</td>\n",
       "      <td>Семь автомобилей горит в субботу утром на стоя...</td>\n",
       "      <td>Воскресенья утром в 10 часов недалеко от город...</td>\n",
       "      <td>В ночь с 19 на 20 августа в районе улицы Степа...</td>\n",
       "      <td>Сегодня утром в районе станции метро «Звёздная...</td>\n",
       "      <td>В среду утром в городе Бауманск произошло пожа...</td>\n",
       "      <td>\\n**Пожар уничтожил несколько автомобилей на с...</td>\n",
       "      <td>В ночь с 13-го на 14 января в Санкт-Петербурге...</td>\n",
       "      <td>\\n\\nВчера вечером на одной из самых оживленных...</td>\n",
       "      <td>Вчера в 22:00 по местному времени дежурным охр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tass.ru/sport/3866330</td>\n",
       "      <td>МОСКВА, 13 декабря. /ТАСС/. Олимпийская чемпио...</td>\n",
       "      <td>Олимпийская чемпионка Елена Веснина стала поче...</td>\n",
       "      <td>ods_tass</td>\n",
       "      <td>1481617927</td>\n",
       "      <td>Олимпийская чемпионка Елена Веснина стала поче...</td>\n",
       "      <td>Олимпийская чемпионка по теннису россиянка Еле...</td>\n",
       "      <td>851</td>\n",
       "      <td>```\\nСегодня в городе состоялась церемония наг...</td>\n",
       "      <td>Санкт-Петербургский городской комитет спорта и...</td>\n",
       "      <td>Двукратная олимпийская чемпионка в парных соре...</td>\n",
       "      <td>\\nElena Vesnina became an honorary citizen of ...</td>\n",
       "      <td>Сегодня в городе Сочи состоялась церемония наг...</td>\n",
       "      <td>Сегодня в городе Сочи прошло торжественное мер...</td>\n",
       "      <td>Сегодня в городе на берегу Черного моря состоя...</td>\n",
       "      <td>\\nЕлена Веснина - выдающаяся российская теннис...</td>\n",
       "      <td>В субботу в Олимпийском парке состоялось торже...</td>\n",
       "      <td>\\n\\nСегодня в Сочи состоялась церемония, на ко...</td>\n",
       "      <td>Елена Васильевна Веснина — российский теннисис...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://rusplt.ru/region-news/barnaul/v-altaysk...</td>\n",
       "      <td>С начала ноября четыре жителя Алтайского края ...</td>\n",
       "      <td>В Алтайском крае под лед провалились четыре че...</td>\n",
       "      <td>buriy</td>\n",
       "      <td>1447147996</td>\n",
       "      <td>В Алтайском крае под лед провалились четыре че...</td>\n",
       "      <td>С начала ноября четыре жителя Алтайского края ...</td>\n",
       "      <td>744</td>\n",
       "      <td>Сегодня утром в селе Барабинка Усть-Коксинског...</td>\n",
       "      <td>Четырех человек удалось вытащить из воды в Бий...</td>\n",
       "      <td>По информации ГУ МЧС по региону, вчера вечером...</td>\n",
       "      <td>Алматинская телевизионная компания «Казахстан»...</td>\n",
       "      <td>Сегодня в поселке Новоселово Алтайского края п...</td>\n",
       "      <td>Сегодня в Бийске произошла трагическая ситуаци...</td>\n",
       "      <td>Пять человек отправились на рыбалку в районе с...</td>\n",
       "      <td>\\n**Трагедия на льду в Алтайском крае: четверо...</td>\n",
       "      <td>Четверо мужчин утонули, провалившись в прорубь...</td>\n",
       "      <td>**Название: Четверо провалились под лед на Алт...</td>\n",
       "      <td>Сегодня утром в одной из деревень Вершинского ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/2002/08/06/chisinau/</td>\n",
       "      <td>Президент Молдавии Владимир Воронин своим указ...</td>\n",
       "      <td>Президент Молдавии уволил главу своей службы о...</td>\n",
       "      <td>lenta</td>\n",
       "      <td>1028592000</td>\n",
       "      <td>Президент Молдавии уволил главу своей службы о...</td>\n",
       "      <td>Президент Молдавии Владимир Воронин своим указ...</td>\n",
       "      <td>697</td>\n",
       "      <td>&gt; Игорь Додон покинул должность в связи с расс...</td>\n",
       "      <td>Начальник Службой государственной безопасности...</td>\n",
       "      <td>Владимир Плантеа, который был назначен премьер...</td>\n",
       "      <td>\\nMoldovan President Nicolae Timofti has sacke...</td>\n",
       "      <td>В пятницу президент Республики Молдова Дорин К...</td>\n",
       "      <td>Министерство внутренних дел Республики Молдова...</td>\n",
       "      <td>Председатель парламента Молдовы Игорь Корман з...</td>\n",
       "      <td>\\nВ молдавской столице Кишинёве сегодня произо...</td>\n",
       "      <td>В четверг президент Молдавии Владимир Воронин ...</td>\n",
       "      <td>\\n\\nВчера президент Молдавии, Игорь Додон, при...</td>\n",
       "      <td>В четверг президент Молдовы Игорь Додон заявил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lenta.ru/news/2017/08/21/annabel/</td>\n",
       "      <td>Посетительнице кинотеатра в Бразилии стало пло...</td>\n",
       "      <td>Бразильянке вызвали скорую после просмотра хор...</td>\n",
       "      <td>lenta</td>\n",
       "      <td>1503273600</td>\n",
       "      <td>Бразильянке вызвали скорую после просмотра хор...</td>\n",
       "      <td>Посетительнице кинотеатра в Бразилии стало пло...</td>\n",
       "      <td>655</td>\n",
       "      <td>```\\nСкорая помощь была вызвана в бразильском ...</td>\n",
       "      <td>Согласно информации сайта Ananova, 24-летняя б...</td>\n",
       "      <td>В Бразилии медики получили званок из кинотеатр...</td>\n",
       "      <td>В Бразилии 20-летняя девушка попросила скорую,...</td>\n",
       "      <td>В Бразилии произошла удивительная история: жен...</td>\n",
       "      <td>В Бразилии произошла необычная история. Житель...</td>\n",
       "      <td>Сегодня утром в больнице Сан-Паулу была госпит...</td>\n",
       "      <td>\\nВ одном из городов Бразилии женщина была вын...</td>\n",
       "      <td>Жительница Бразилии, просмотревшая фильм ужасо...</td>\n",
       "      <td>\\n\\nВ последние выходные в Бразилии произошел ...</td>\n",
       "      <td>В Санта-Розе (штат Калифорния) в США произошло...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0             http://www.fontanka.ru/2013/10/16/017/   \n",
       "1                      https://tass.ru/sport/3866330   \n",
       "2  http://rusplt.ru/region-news/barnaul/v-altaysk...   \n",
       "3         https://lenta.ru/news/2002/08/06/chisinau/   \n",
       "4          https://lenta.ru/news/2017/08/21/annabel/   \n",
       "\n",
       "                                                text  \\\n",
       "0  Пожар произошел минувшей ночью в Московском ра...   \n",
       "1  МОСКВА, 13 декабря. /ТАСС/. Олимпийская чемпио...   \n",
       "2  С начала ноября четыре жителя Алтайского края ...   \n",
       "3  Президент Молдавии Владимир Воронин своим указ...   \n",
       "4  Посетительнице кинотеатра в Бразилии стало пло...   \n",
       "\n",
       "                                               title          source  \\\n",
       "0         На стоянке на Звездной обгорело семь машин  taiga_fontanka   \n",
       "1  Олимпийская чемпионка Елена Веснина стала поче...        ods_tass   \n",
       "2  В Алтайском крае под лед провалились четыре че...           buriy   \n",
       "3  Президент Молдавии уволил главу своей службы о...           lenta   \n",
       "4  Бразильянке вызвали скорую после просмотра хор...           lenta   \n",
       "\n",
       "    timestamp                                      cleaned_title  \\\n",
       "0  1381911180         На стоянке на Звездной обгорело семь машин   \n",
       "1  1481617927  Олимпийская чемпионка Елена Веснина стала поче...   \n",
       "2  1447147996  В Алтайском крае под лед провалились четыре че...   \n",
       "3  1028592000  Президент Молдавии уволил главу своей службы о...   \n",
       "4  1503273600  Бразильянке вызвали скорую после просмотра хор...   \n",
       "\n",
       "                                        cleaned_text  len_cleaned_text  \\\n",
       "0  Пожар произошел минувшей ночью в Московском ра...               476   \n",
       "1  Олимпийская чемпионка по теннису россиянка Еле...               851   \n",
       "2  С начала ноября четыре жителя Алтайского края ...               744   \n",
       "3  Президент Молдавии Владимир Воронин своим указ...               697   \n",
       "4  Посетительнице кинотеатра в Бразилии стало пло...               655   \n",
       "\n",
       "                                       gen_llama3_8b  \\\n",
       "0  ```\\nВ результате пожара в ночном клубе «Мечта...   \n",
       "1  ```\\nСегодня в городе состоялась церемония наг...   \n",
       "2  Сегодня утром в селе Барабинка Усть-Коксинског...   \n",
       "3  > Игорь Додон покинул должность в связи с расс...   \n",
       "4  ```\\nСкорая помощь была вызвана в бразильском ...   \n",
       "\n",
       "                                  gen_llama3_8b_lora  \\\n",
       "0  В ночь с 28-го апреля на 29-е в поселковом цен...   \n",
       "1  Санкт-Петербургский городской комитет спорта и...   \n",
       "2  Четырех человек удалось вытащить из воды в Бий...   \n",
       "3  Начальник Службой государственной безопасности...   \n",
       "4  Согласно информации сайта Ananova, 24-летняя б...   \n",
       "\n",
       "                                 gen_mistral_7b_lora  \\\n",
       "0  Семь автомобилей горит в субботу утром на стоя...   \n",
       "1  Двукратная олимпийская чемпионка в парных соре...   \n",
       "2  По информации ГУ МЧС по региону, вчера вечером...   \n",
       "3  Владимир Плантеа, который был назначен премьер...   \n",
       "4  В Бразилии медики получили званок из кинотеатр...   \n",
       "\n",
       "                                      gen_mistral_7b  \\\n",
       "0  Воскресенья утром в 10 часов недалеко от город...   \n",
       "1  \\nElena Vesnina became an honorary citizen of ...   \n",
       "2  Алматинская телевизионная компания «Казахстан»...   \n",
       "3  \\nMoldovan President Nicolae Timofti has sacke...   \n",
       "4  В Бразилии 20-летняя девушка попросила скорую,...   \n",
       "\n",
       "                                         gen_qwen_7b  \\\n",
       "0  В ночь с 19 на 20 августа в районе улицы Степа...   \n",
       "1  Сегодня в городе Сочи состоялась церемония наг...   \n",
       "2  Сегодня в поселке Новоселово Алтайского края п...   \n",
       "3  В пятницу президент Республики Молдова Дорин К...   \n",
       "4  В Бразилии произошла удивительная история: жен...   \n",
       "\n",
       "                                    gen_qwen_7b_lora  \\\n",
       "0  Сегодня утром в районе станции метро «Звёздная...   \n",
       "1  Сегодня в городе Сочи прошло торжественное мер...   \n",
       "2  Сегодня в Бийске произошла трагическая ситуаци...   \n",
       "3  Министерство внутренних дел Республики Молдова...   \n",
       "4  В Бразилии произошла необычная история. Житель...   \n",
       "\n",
       "                                        gen_llama_8b  \\\n",
       "0  В среду утром в городе Бауманск произошло пожа...   \n",
       "1  Сегодня в городе на берегу Черного моря состоя...   \n",
       "2  Пять человек отправились на рыбалку в районе с...   \n",
       "3  Председатель парламента Молдовы Игорь Корман з...   \n",
       "4  Сегодня утром в больнице Сан-Паулу была госпит...   \n",
       "\n",
       "                                        gen_yagpt_8b  \\\n",
       "0  \\n**Пожар уничтожил несколько автомобилей на с...   \n",
       "1  \\nЕлена Веснина - выдающаяся российская теннис...   \n",
       "2  \\n**Трагедия на льду в Алтайском крае: четверо...   \n",
       "3  \\nВ молдавской столице Кишинёве сегодня произо...   \n",
       "4  \\nВ одном из городов Бразилии женщина была вын...   \n",
       "\n",
       "                                       gen_rugpt_13b  \\\n",
       "0  В ночь с 13-го на 14 января в Санкт-Петербурге...   \n",
       "1  В субботу в Олимпийском парке состоялось торже...   \n",
       "2  Четверо мужчин утонули, провалившись в прорубь...   \n",
       "3  В четверг президент Молдавии Владимир Воронин ...   \n",
       "4  Жительница Бразилии, просмотревшая фильм ужасо...   \n",
       "\n",
       "                                      gen_tliteit_7b  \\\n",
       "0  \\n\\nВчера вечером на одной из самых оживленных...   \n",
       "1  \\n\\nСегодня в Сочи состоялась церемония, на ко...   \n",
       "2  **Название: Четверо провалились под лед на Алт...   \n",
       "3  \\n\\nВчера президент Молдавии, Игорь Додон, при...   \n",
       "4  \\n\\nВ последние выходные в Бразилии произошел ...   \n",
       "\n",
       "                               gen_llama_8b_instruct  \n",
       "0  Вчера в 22:00 по местному времени дежурным охр...  \n",
       "1  Елена Васильевна Веснина — российский теннисис...  \n",
       "2  Сегодня утром в одной из деревень Вершинского ...  \n",
       "3  В четверг президент Молдовы Игорь Додон заявил...  \n",
       "4  В Санта-Розе (штат Калифорния) в США произошло...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"inference_result/df_test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834502ab-6c73-435b-bfa4-73a7e24cd95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'text', 'title', 'source', 'timestamp', 'cleaned_title',\n",
       "       'cleaned_text', 'len_cleaned_text', 'gen_llama3_8b',\n",
       "       'gen_llama3_8b_lora', 'gen_mistral_7b_lora', 'gen_mistral_7b',\n",
       "       'gen_qwen_7b', 'gen_qwen_7b_lora', 'gen_llama_8b', 'gen_yagpt_8b',\n",
       "       'gen_rugpt_13b', 'gen_tliteit_7b', 'gen_llama_8b_instruct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e585151-3fde-4e35-8318-56e109775883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████████████████████████████████████████                                                                                                                | 4/11 [00:53<01:37, 13.96s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm_a\n",
    "\n",
    "metric = {}\n",
    "\n",
    "for col in tqdm_a(['gen_llama3_8b',\n",
    "       'gen_llama3_8b_lora', 'gen_mistral_7b_lora', 'gen_mistral_7b',\n",
    "       'gen_qwen_7b', 'gen_qwen_7b_lora', 'gen_llama_8b', 'gen_yagpt_8b',\n",
    "       'gen_rugpt_13b', 'gen_tliteit_7b', 'gen_llama_8b_instruct']):\n",
    "    \n",
    "    sub_df = df.sample(n=100)\n",
    "    candidates, references = sub_df[col].tolist(), sub_df['cleaned_text'].tolist()\n",
    "\n",
    "    MAX_LENGTH = 2048\n",
    "\n",
    "    metrics_list = []\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        # We use stemms for metrics without transformers and LLM\n",
    "        candidate_stems = \" \".join(preprocess_text(candidate, stemmer))\n",
    "        reference_stems = \" \".join(preprocess_text(reference, stemmer))\n",
    "        \n",
    "        # ROUGE\n",
    "        rouge1 = rouge_n(candidate_stems, reference_stems, n=1)\n",
    "        rouge2 = rouge_n(candidate_stems, reference_stems, n=2)\n",
    "        rougel = rouge_l(candidate_stems[:MAX_LENGTH], reference_stems[:MAX_LENGTH]) \n",
    "        \n",
    "        result = {\n",
    "            'ROUGE-1 recall': rouge1['rouge-1_recall'],\n",
    "            'ROUGE-1 precision': rouge1['rouge-1_precision'],\n",
    "            'ROUGE-1 f1': rouge1['rouge-1_f1'],\n",
    "        }\n",
    "        result |= {\n",
    "            'ROUGE-2 recall': rouge2['rouge-2_recall'],\n",
    "            'ROUGE-2 precision': rouge2['rouge-2_precision'],\n",
    "            'ROUGE-2 f1': rouge2['rouge-2_f1'],\n",
    "        }\n",
    "        result |= {\n",
    "            'ROUGE-L recall': rougel['rouge-l_recall'],\n",
    "            'ROUGE-L precision': rougel['rouge-l_precision'],\n",
    "            'ROUGE-L f1': rougel['rouge-l_f1']\n",
    "        }     \n",
    "\n",
    "        # BLEU\n",
    "        bleu_results = bleu_metric.compute(predictions=[candidate_stems], references=[reference_stems])\n",
    "        result |= {'BLEU': bleu_results['bleu']}\n",
    "\n",
    "        # METEOR\n",
    "        meteor_results = meteor.compute(predictions=[candidate_stems], references=[reference_stems])\n",
    "        result |= {'METEOR': float(meteor_results['meteor'])}\n",
    "\n",
    "        # Perplexity\n",
    "        perplexity = calculate_perplexity(get_loss(ppl_model, ppl_tokenizer, candidate))\n",
    "        result |= {\"Perplexity\": perplexity}\n",
    "        \n",
    "        metrics_list.append(result)\n",
    "\n",
    "    bertscore_metric = calculate_bertscore(bertscore_model, references, candidates)\n",
    "    bleurt_metric = calculate_bleurt(bleurt_model, bleurt_tokenizer, references, candidates)\n",
    "    \n",
    "    metrics_dict = {k: round(float(np.mean([d[k] for d in metrics_list])), 4) for k in metrics_list[0]} \n",
    "    metric[col] = metrics_dict | bertscore_metric | bleurt_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10455845-843e-48e1-bdaf-e0335aeccb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_llama3_8b</th>\n",
       "      <th>gen_llama3_8b_lora</th>\n",
       "      <th>gen_mistral_7b_lora</th>\n",
       "      <th>gen_mistral_7b</th>\n",
       "      <th>gen_qwen_7b</th>\n",
       "      <th>gen_qwen_7b_lora</th>\n",
       "      <th>gen_llama_8b</th>\n",
       "      <th>gen_yagpt_8b</th>\n",
       "      <th>gen_rugpt_13b</th>\n",
       "      <th>gen_tliteit_7b</th>\n",
       "      <th>gen_llama_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE-1 recall</th>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.7556</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.8589</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-1 precision</th>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.5266</td>\n",
       "      <td>0.4807</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-1 f1</th>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.6206</td>\n",
       "      <td>0.5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-2 recall</th>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.4641</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.4097</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-2 precision</th>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.6703</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>0.4427</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.3888</td>\n",
       "      <td>0.3183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-2 f1</th>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.4543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-L recall</th>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.6364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-L precision</th>\n",
       "      <td>0.3174</td>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.2819</td>\n",
       "      <td>0.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-L f1</th>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.3156</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.3711</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METEOR</th>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perplexity</th>\n",
       "      <td>17.9245</td>\n",
       "      <td>16.3360</td>\n",
       "      <td>24.0707</td>\n",
       "      <td>21.2489</td>\n",
       "      <td>12.0252</td>\n",
       "      <td>13.6952</td>\n",
       "      <td>14.3055</td>\n",
       "      <td>9.7130</td>\n",
       "      <td>10.9913</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>19.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERTscore_precision</th>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.6463</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERTscore_recall</th>\n",
       "      <td>0.6206</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERTscore_f1</th>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEURT</th>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gen_llama3_8b  gen_llama3_8b_lora  gen_mistral_7b_lora  \\\n",
       "ROUGE-1 recall              0.6456              0.6418               0.5072   \n",
       "ROUGE-1 precision           0.5325              0.9090               0.9397   \n",
       "ROUGE-1 f1                  0.5133              0.7209               0.6204   \n",
       "ROUGE-2 recall              0.4704              0.4641               0.3716   \n",
       "ROUGE-2 precision           0.3684              0.6703               0.7100   \n",
       "ROUGE-2 f1                  0.3658              0.5250               0.4598   \n",
       "ROUGE-L recall              0.3716              0.3486               0.2936   \n",
       "ROUGE-L precision           0.3174              0.5089               0.5785   \n",
       "ROUGE-L f1                  0.2925              0.3952               0.3649   \n",
       "BLEU                        0.0010              0.0075               0.0100   \n",
       "METEOR                      0.0787              0.1071               0.0911   \n",
       "Perplexity                 17.9245             16.3360              24.0707   \n",
       "BERTscore_precision         0.5947              0.6823               0.6859   \n",
       "BERTscore_recall            0.6206              0.6603               0.6450   \n",
       "BERTscore_f1                0.6066              0.6708               0.6644   \n",
       "BLEURT                      0.1825              0.2604               0.2569   \n",
       "\n",
       "                     gen_mistral_7b  gen_qwen_7b  gen_qwen_7b_lora  \\\n",
       "ROUGE-1 recall               0.7556       0.9567            0.9614   \n",
       "ROUGE-1 precision            0.4562       0.5266            0.4807   \n",
       "ROUGE-1 f1                   0.5525       0.6560            0.6261   \n",
       "ROUGE-2 recall               0.5537       0.7830            0.7920   \n",
       "ROUGE-2 precision            0.3303       0.4210            0.3899   \n",
       "ROUGE-2 f1                   0.4025       0.5286            0.5107   \n",
       "ROUGE-L recall               0.4384       0.5696            0.5783   \n",
       "ROUGE-L precision            0.2586       0.2979            0.2790   \n",
       "ROUGE-L f1                   0.3156       0.3766            0.3674   \n",
       "BLEU                         0.0018       0.0052            0.0060   \n",
       "METEOR                       0.0879       0.1604            0.1612   \n",
       "Perplexity                  21.2489      12.0252           13.6952   \n",
       "BERTscore_precision          0.6219       0.6463            0.6366   \n",
       "BERTscore_recall             0.6428       0.6757            0.6700   \n",
       "BERTscore_f1                 0.6319       0.6604            0.6527   \n",
       "BLEURT                       0.2177       0.2862            0.2681   \n",
       "\n",
       "                     gen_llama_8b  gen_yagpt_8b  gen_rugpt_13b  \\\n",
       "ROUGE-1 recall             0.8589        0.9364         0.5526   \n",
       "ROUGE-1 precision          0.6079        0.5664         0.9004   \n",
       "ROUGE-1 f1                 0.6457        0.6732         0.6357   \n",
       "ROUGE-2 recall             0.6741        0.7533         0.4097   \n",
       "ROUGE-2 precision          0.4610        0.4427         0.6869   \n",
       "ROUGE-2 f1                 0.4944        0.5317         0.4744   \n",
       "ROUGE-L recall             0.4966        0.5608         0.3163   \n",
       "ROUGE-L precision          0.3432        0.3196         0.5527   \n",
       "ROUGE-L f1                 0.3608        0.3864         0.3711   \n",
       "BLEU                       0.0033        0.0085         0.0081   \n",
       "METEOR                     0.1326        0.1648         0.1157   \n",
       "Perplexity                14.3055        9.7130        10.9913   \n",
       "BERTscore_precision        0.6312        0.6491         0.6909   \n",
       "BERTscore_recall           0.6578        0.6784         0.6556   \n",
       "BERTscore_f1               0.6435        0.6632         0.6721   \n",
       "BLEURT                     0.2429        0.3143         0.2708   \n",
       "\n",
       "                     gen_tliteit_7b  gen_llama_8b_instruct  \n",
       "ROUGE-1 recall               0.9712                 0.9776  \n",
       "ROUGE-1 precision            0.4674                 0.3735  \n",
       "ROUGE-1 f1                   0.6206                 0.5321  \n",
       "ROUGE-2 recall               0.8145                 0.8395  \n",
       "ROUGE-2 precision            0.3888                 0.3183  \n",
       "ROUGE-2 f1                   0.5175                 0.4543  \n",
       "ROUGE-L recall               0.6037                 0.6364  \n",
       "ROUGE-L precision            0.2819                 0.2363  \n",
       "ROUGE-L f1                   0.3775                 0.3388  \n",
       "BLEU                         0.0103                 0.0018  \n",
       "METEOR                       0.1776                 0.1528  \n",
       "Perplexity                   8.9522                19.8216  \n",
       "BERTscore_precision          0.6319                 0.6157  \n",
       "BERTscore_recall             0.6695                 0.6636  \n",
       "BERTscore_f1                 0.6500                 0.6386  \n",
       "BLEURT                       0.3023                 0.2603  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric = pd.DataFrame(metric)\n",
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf502c8-8da6-42c6-a548-8a799922e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric.to_excel(\"inference_result/auto_metric_3.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_vkr",
   "language": "python",
   "name": "myenv_vkr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
